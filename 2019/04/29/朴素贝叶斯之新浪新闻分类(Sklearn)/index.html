<!--
	作者：Sariay
	时间：2018-09-25
	描述：There may be a bug, but don't worry, QiLing(器灵) says that it can work normally!
-->


	<!DOCTYPE html>
	<html>
		

<head><meta name="generator" content="Hexo 3.8.0">
	<title>朴素贝叶斯之新浪新闻分类(Sklearn)</title>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="apple-mobile-web-app-title" content="Amaze UI">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
    <meta name="author" content="miraitowa">
    <meta name="keywords" content="">
    <meta name="description" content="">
   	<!-- css -->
	<link rel="stylesheet" href="/css/style.css">

	<!-- favicon -->
	<link href="/img/favicon.ico" rel="Shortcut Icon" type="image/ico">
	
	<!-- font-awesome -->
	<link href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
</head>

	<body>	
		<!--Preloader-->
<div id="preloader">
	<div id="status">
		<img alt="PRELOADER" src="/img/logo.png">
	</div>
</div>
<!--Preloader end-->

<!-- header -->

	<header id="header-bg-2">

	
		<div id="cd-logo"><a href="/"><img src="/img/logo.png" alt="Logo"></a></div>
	
	
	<!-- motto or description -->
		
 		<p class="motto"></p>
	
	
	<!-- current page name or title -->
	
		
		
			
			<p class="page-name">当前文章&nbsp;:&nbsp;《朴素贝叶斯之新浪新闻分类(Sklearn)》</p>
			
		
	
	
	<!-- others: such as change-bg, time... -->
	<p class="page-name-other">
		5/4/2019 
		<style type="text/css">
	header:after {
		content: '';
		position: relative;
		top: 0;
		left: 0;
		height: 100%;
		width: 100%;
		background: #222222;
		opacity: .5;
		z-index: -1;
	}
	
	.change-header-bg{
		font-style: normal;
	}
	.change-header-bg i{
		text-align: center;
		cursor: pointer;
		pointer-events: bounding-box;
	}
	@media(max-width:512px) {
		.change-header-bg {
			display: none;
			visibility: hidden;
		}
	}
	
</style>

<script type="text/javascript">
	function changeHeaderBg(){
		var random_bg = Math.floor(Math.random() * 109 + 1);
		var bg = 'url(https://miraitowa.github.io/Random-img/' + random_bg + '.jpg)';
		$("#header-bg-2").css("background-image", bg);
	}
</script>

<span class="change-header-bg">
	——&nbsp;<i class="fa fa-camera-retro" onclick="changeHeaderBg()"></i>	
</span>
	</p>		
</header>

<!-- nav -->
<div id="cd-nav">
	<a href="#0" title="menu" class="cd-nav-trigger"><span></span></a>

	<nav id="cd-main-nav">
		<ul>
			
      		<li class="fa fa-/">
           		<a href="/" title="主页">主页</a>	
      		</li>
    		
      		<li class="fa fa-/archives">
           		<a href="/archives" title="归档">归档</a>	
      		</li>
    		
      		<li class="fa fa-/categories">
           		<a href="/categories" title="分类">分类</a>	
      		</li>
    		
      		<li class="fa fa-/gallery">
           		<a href="/gallery" title="相册">相册</a>	
      		</li>
    		
      		<li class="fa fa-/about">
           		<a href="/about" title="关于">关于</a>	
      		</li>
    		
      		<li class="fa fa-/tags">
           		<a href="/tags" title="友链">友链</a>	
      		</li>
    		
    		
        	
		</ul>
	</nav>
</div>

		<!--main-->
		<main> 
		<div class="page-container">
		<!-- content srart -->
<div class="am-g am-g-fixed blog-fixed blog-content">
	<div class="am-u-md-8 am-u-sm-12">

		<article class="am-article blog-article-p">

			<div class="am-article-hd">
				


				<h1 class="am-article-title blog-text-center">
					
					
	
		<a href="/2019/04/29/朴素贝叶斯之新浪新闻分类(Sklearn)/" itemprop="url">		
			朴素贝叶斯之新浪新闻分类(Sklearn)		
		</a>
	

				</h1>

				<p class="am-article-meta blog-text-center">
					<span>
						<i class="fa fa-clock-o"></i> 
						<a href="/2019/04/29/朴素贝叶斯之新浪新闻分类(Sklearn)/" itemprop="url">
	<time datetime="2019-04-29T12:51:30.270Z" itemprop="datePublished">
  		2019-04-29
  </time>
</a>    
&nbsp;
					</span>
					
					<span>						
						
					</span>
				</p>
			</div>

			<div class="am-article-bd">
				<div class="content" id="post-content">
					
						<h3 id="朴素贝叶斯之新浪新闻分类-Sklearn"><a href="#朴素贝叶斯之新浪新闻分类-Sklearn" class="headerlink" title="朴素贝叶斯之新浪新闻分类(Sklearn)"></a>朴素贝叶斯之新浪新闻分类(Sklearn)</h3><h3 id="1-中文语句切分"><a href="#1-中文语句切分" class="headerlink" title="1 中文语句切分"></a>1 中文语句切分</h3><p>考虑一个问题，英文的语句可以通过非字母和非数字进行切分，但是汉语句子呢？就比如我打的这一堆字，该如何进行切分呢？我们自己写个规则？</p>
<p>幸运地是，这部分的工作不需要我们自己做了，可以直接使用第三方分词组件，即jieba，没错就是”结巴”。</p>
<p>jieba已经兼容Python2和Python3，使用如下指令直接安装即可：</p>
<pre><code>pip3 install jieba
</code></pre><p>Python中文分词组件使用简单：</p>
<blockquote>
<ol>
<li><p>官方教程：<a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">https://github.com/fxsjy/jieba</a></p>
</li>
<li><p>民间教程：<a href="https://www.oschina.net/p/jieba" target="_blank" rel="noopener">https://www.oschina.net/p/jieba</a></p>
</li>
</ol>
</blockquote>
<p>新闻分类数据集我也已经准备好，可以到我的Github进行下载：<a href="https://github.com/miraitowa/Machine-Learning" target="_blank" rel="noopener">https://github.com/miraitowa/Machine-Learning</a></p>
<p>数据集是直接从网上下载得到：</p>
<p><img src="https://i.imgur.com/Ov5AjPq.png" alt=""></p>
<p>数据集已经准备好，接下来，让我们直接进入正题。切分中文语句，编写如下代码：</p>
<pre><code>import pandas as pd
import numpy
import jieba
#pip install jieba

** 数据源 **

df_news = pd.read_table(&#39;./data/val.txt&#39;, names=[&#39;category&#39;, &#39;theme&#39;,&#39;URL&#39;,&#39;content&#39;],encoding=&#39;utf-8&#39;)
df_news = df_news.dropna()
df_news.head()
</code></pre><p><img src="https://i.imgur.com/4RXYaHu.png" alt=""></p>
<pre><code>df_news.shape #查看数据类型
</code></pre><p><img src="https://i.imgur.com/uKHmEyn.png" alt=""></p>
<p><strong> 分词：使用结巴分词器 </strong></p>
<pre><code>content = df_news.content.values.tolist()
print (content[1000])
</code></pre><p><img src="https://i.imgur.com/EfiW2DW.png" alt=""></p>
<pre><code>content_S = []
for line in content:
    current_segment = jieba.lcut(line)
    if len(current_segment) 1 and current_segment != &#39;\r\n&#39;:  #换行符
       content_S.append(current_segment)

content_S[1000]
</code></pre><p><img src="https://i.imgur.com/GG9NZjp.png" alt=""></p>
<pre><code>df_content = pd.DataFrame({&#39;content_S&#39;:content_S})
df_content.head()
</code></pre><p><img src="https://i.imgur.com/SH6TzEO.png" alt=""></p>
<pre><code>stopwords = pd.read_csv(&quot;stopwords.txt&quot;,index_col=False,sep=&quot;\t&quot;,quoting=3,names=[&#39;stopwords&#39;],encoding=&#39;utf-8&#39;)
stopwords.head(10)
</code></pre><p><img src="https://i.imgur.com/lIR0SXt.png" alt=""></p>
<pre><code>def drop_stopwords(contents,stopwords):
    contents_clean = []
    all_words = []
    for line in contents:
        line_clean = []
        for word in line:
            if word in stopwords:
                continue
            line_clean.append(word)
            all_words.append(str(word))
        contents_clean.append(line_clean)
    return contents_clean,all_words

contents = df_content.content_S.values.tolist()
#stopwords = stopwords.stopword.values.tolist()
contents_clean,all_words = drop_stopwords(contents,stopwords)

df_content=pd.DataFrame({&#39;contents_clean&#39;:contents_clean})
df_content.head()
</code></pre><p><img src="https://i.imgur.com/mwC83ny.png" alt=""></p>
<pre><code>df_all_words=pd.DataFrame({&#39;all_words&#39;:all_words})
df_all_words.head()
</code></pre><p><img src="https://i.imgur.com/7naj1jf.png" alt=""></p>
<pre><code>words_count=df_all_words.groupby(by=[&#39;all_words&#39;])[&#39;all_words&#39;].agg({&quot;count&quot;:numpy.size})
words_count=words_count.reset_index().sort_values(by=[&quot;count&quot;],ascending=False)
words_count.head()
</code></pre><p><img src="https://i.imgur.com/ecgEYdx.png" alt=""></p>
<pre><code>from wordcloud import WordCloud
import matplotlib.pyplot as plt
%matplotlib inline
import matplotlib

matplotlib.rcParams[&#39;figure.figsize&#39;] = (10.0, 5.0)

wordcloud = WordCloud(font_path=&quot;./data/simhei.ttf&quot;,background_color=&quot;white&quot;,max_font_size=80)
word_frequence = {x[0]:x[1] for x in words_count.head(100).values}
wordcloud=wordcloud.fit_words(word_frequence)
plt.imshow(wordcloud)
</code></pre><p><img src="https://i.imgur.com/HHMs6T2.png" alt=""></p>
<h3 id="TF-IDF-提取关键词"><a href="#TF-IDF-提取关键词" class="headerlink" title="TF-IDF: 提取关键词"></a>TF-IDF: 提取关键词</h3><pre><code>import jieba.analyse
index = 1000
print (df_news[&#39;content&#39;][index])
content_S_str = &quot;&quot;.join(content_S[index])
print (&quot; &quot;.join(jieba.analyse.extract_tags(content_S_str, topK=5, withWeight=False)))
</code></pre><p><img src="https://i.imgur.com/vTLSMTO.png" alt=""></p>
<h3 id="LDA-主题模型"><a href="#LDA-主题模型" class="headerlink" title="LDA: 主题模型"></a>LDA: 主题模型</h3><p>格式要求：list of list形式，分词好的整个预料</p>
<pre><code>from gensim import corpora, models, similarities
import gensim

#做映射 相当于词袋
dictionary = corpora.Dictionary(contents_clean)
corpus = [dictionary.doc2bow(sentence) for sentence in contents_clean]

lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary,num_topics=20)

#一号分类结束

print(lda.print_topic(1, topn=6))
</code></pre><p><img src="https://i.imgur.com/R2KLIo7.png" alt=""></p>
<pre><code>for topic in lda.print_topics(num_topics=20, num_words=5):
    print (topic[1])
</code></pre><p><img src="https://i.imgur.com/yI2f8YD.png" alt=""></p>
<pre><code>df_train=pd.DataFrame({&#39;contents_clean&#39;:contents_clean,&#39;label&#39;:df_news[&#39;category&#39;]})
df_train.tail()
</code></pre><p><img src="https://i.imgur.com/wmFOxZE.png" alt=""></p>
<pre><code>df_train.label.unique()
</code></pre><p><img src="https://i.imgur.com/Ya8G2PT.png" alt=""></p>
<pre><code>label_mapping = {&quot;汽车&quot;: 1, &quot;财经&quot;: 2, &quot;科技&quot;: 3, &quot;健康&quot;: 4, &quot;体育&quot;:5, &quot;教育&quot;: 6,&quot;文化&quot;: 7,&quot;军事&quot;: 8,&quot;娱乐&quot;: 9,&quot;时尚&quot;: 0}
df_train[&#39;label&#39;] = df_train[&#39;label&#39;].map(label_mapping)
df_train.head()
</code></pre><p><img src="https://i.imgur.com/BTAlxpm.png" alt=""></p>
<pre><code>from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(df_train[&#39;contents_clean&#39;].values, df_train[&#39;label&#39;].values, random_state=1)

#x_train = x_train.flatten()
x_train[0][3]

words = []
for line_index in range(len(x_train)):
    try:
        #x_train[line_index][word_index] = str(x_train[line_index][word_index])
        words.append(&#39; &#39;.join(x_train[line_index]))
    except:
        print (line_index,word_index)
words[0]   
</code></pre><p><img src="https://i.imgur.com/MgUBRX3.png" alt=""></p>
<pre><code>print(len(words))
</code></pre><p><strong>3750</strong></p>
<pre><code>from sklearn.feature_extraction.text import CountVectorizer
texts=[&quot;dog cat fish&quot;,&quot;dog cat cat&quot;,&quot;fish bird&quot;, &#39;bird&#39;]
cv = CountVectorizer()
cv_fit=cv.fit_transform(texts)

print(cv.get_feature_names())
print(cv_fit.toarray())


print(cv_fit.toarray().sum(axis=0))
</code></pre><p><img src="https://i.imgur.com/Xnk6Xmt.png" alt=""></p>
<pre><code>from sklearn.feature_extraction.text import CountVectorizer
texts=[&quot;dog cat fish&quot;,&quot;dog cat cat&quot;,&quot;fish bird&quot;, &#39;bird&#39;]
cv = CountVectorizer(ngram_range=(1,4))
cv_fit=cv.fit_transform(texts)

print(cv.get_feature_names())
print(cv_fit.toarray())


print(cv_fit.toarray().sum(axis=0))
</code></pre><p><img src="https://i.imgur.com/13UJWmo.png" alt=""></p>
<pre><code>from sklearn.feature_extraction.text import CountVectorizer

vec = CountVectorizer(analyzer=&#39;word&#39;, max_features=4000,  lowercase = False)
vec.fit(words)
</code></pre><p><img src="https://i.imgur.com/4LZ6cqj.png" alt=""></p>
<pre><code>from sklearn.naive_bayes import MultinomialNB
classifier = MultinomialNB()
classifier.fit(vec.transform(words), y_train)
</code></pre><p><strong>MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)</strong></p>
<pre><code>test_words = []
for line_index in range(len(x_test)):
    try:
        #x_train[line_index][word_index] = str(x_train[line_index][word_index])
        test_words.append(&#39; &#39;.join(x_test[line_index]))
    except:
         print (line_index,word_index)
test_words[0]
</code></pre><p><img src="https://i.imgur.com/CYzSf2f.png" alt=""></p>
<pre><code>print(len(test_words))
</code></pre><p><strong>1250</strong></p>
<pre><code>classifier.score(vec.transform(test_words), y_test)
</code></pre><p><strong>0.7928</strong></p>
<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(analyzer=&#39;word&#39;, max_features=4000,  lowercase = False)
vectorizer.fit(words)
</code></pre><p><img src="https://i.imgur.com/O1QWohz.png" alt=""></p>
<pre><code>from sklearn.naive_bayes import MultinomialNB
classifier = MultinomialNB()
classifier.fit(vectorizer.transform(words), y_train)
</code></pre><p><img src="https://i.imgur.com/U00CjBk.png" alt=""></p>
<pre><code>classifier.score(vectorizer.transform(test_words), y_test)
</code></pre><p><img src="https://i.imgur.com/qQz19zX.png" alt=""></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol>
<li><p>在训练朴素贝叶斯分类器之前，要处理好训练集，文本的清洗还是有很多需要学习的东西。</p>
</li>
<li><p>根据提取的分类特征将文本向量化，然后训练朴素贝叶斯分类器。</p>
</li>
</ol>

					
				</div>
			</div>
		</article>

		<ul class="am-pagination">
    
    	<li class="am-pagination-prev">
   		<a class="pull-left" href="/2019/05/03/《机器学习实战》学习笔记(一) k-近邻算法(手写识别系统实战)/" title="《机器学习实战》学习笔记(一) k-近邻算法(手写识别系统实战)">
      		&laquo; 上一篇
		</a>
		</li>
	
	
		<li class="am-pagination-next">
		<a class="pull-right" href="/2019/04/29/持续集成服务(CI)漏洞挖掘/" title="持续集成服务(CI)漏洞挖掘">
			下一篇 &raquo;
		</a>
		</li>
	 
 </ul>
        

		<div class="theme-annie-comment-button-container">
	<button id="annie-comment-button" class="theme-annie-comment-button" onclick="Annie_Comment()">
		加载评论
		<!--加载评论-->
	</button>
</div>

<div id="annie-comment-container" class="theme-annie-comment-main-container">

	
		
			<!-- comment gitalk -->
			<!-- show gitalk comment -->

  <div id="gitalk-container"></div>


<!-- gitalk`s css & js -->
<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<link rel="stylesheet" href="/css/comment.css">
<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<script type="text/javascript">
	//thanks O-R
	//https://github.com/gitalk/gitalk/issues/102#issuecomment-382970552
	//去除尾部匹配正则数组的字符串  
	//remove redundant characters
	String.prototype.trimEnd = function(regStr) {
		var result = this;
		if(regStr == undefined || regStr == null || regStr == "") {
			return result;
		}
		var array = regStr.split(',');

		if(array.length > 0) {

			var c = array.shift();
			var str = this;
			var i = str.length;
			var rg = new RegExp(c);
			var matchArr = str.match(rg);

			if(matchArr != undefined && matchArr != null && matchArr.length > 0) {
				var matchStr = matchArr[0].replace(/\\/g, "\\\\").replace(/\*/g, "\\*")
					.replace(/\+/g, "\\+").replace(/\|/g, "\\|")
					.replace(/\{/g, "\\{").replace(/\}/g, "\\}")
					.replace(/\(/g, "\\(").replace(/\)/g, "\\)")
					.replace(/\^/g, "\\^").replace(/\$/g, "\\$")
					.replace(/\[/g, "\\[").replace(/\]/g, "\\]")
					.replace(/\?/g, "\\?").replace(/\,/g, "\\,")
					.replace(/\./g, "\\.").replace(/\&/g, "\\&");
				matchStr = matchStr + '$';
				result = str.replace(new RegExp(matchStr), "");
			}

			if(array.length > 0) {
				return result.trimEnd(array.join())
			} else {
				return result;
			}
		}
	};

	//create gitalk
	var gitalk = new Gitalk({
		clientID: '74a83cc9b15a1cf53e10',
		clientSecret: 'b62af8b132c33178adcb0098e2315806e2e57cae',
		//id: window.location.pathname,
		// id: (window.location.pathname).split("/").pop().substring(0, 49),
		id: md5(location.href.trimEnd('#.*$,\\?.*$,index.html$')),
		repo: 'Annie-Gitalk',
		owner: 'miraitowa',
		admin: 'miraitowa',
		distractionFreeMode: 'true',
	})
	gitalk.render('gitalk-container');
</script>
		
	

</div>

<script type="text/javascript">
	/* Show Comment */
	var Annie_Comment = function() {
		function Show_Hidden(obj) {
			obj.style.display = 'block';
		}
		
		//var obutton = $('#annie-comment-button');
		//var obutton = $('#annie-comment-container');
		var obutton = document.getElementById("annie-comment-button" || "0");
		var odiv = document.getElementById("annie-comment-container");
		if( 'obutton' ) {
			obutton.onclick = function() {
				Show_Hidden(odiv);
				$("#annie-comment-button").css("display", 'none');
				return false;
			}
		}
	};

	(function Annie_Init() {
		Annie_Comment();
	})();
</script>
		
		<!--
	时间：2018-09-24
	描述：The TOC module refers to 'https://github.com/codefine/hexo-theme-mellow', include toc.ejs、toc.js、toc.css. All rights reserved by codefine. 
-->

	
		<aside class="post-widget">
			<nav class="post-toc-wrap" id="post-toc">
				
					<strong>文章目录</strong>
				
				
				<!--toc(post.content)-->
				<ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#朴素贝叶斯之新浪新闻分类-Sklearn"><span class="post-toc-text">朴素贝叶斯之新浪新闻分类(Sklearn)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#1-中文语句切分"><span class="post-toc-text">1 中文语句切分</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#TF-IDF-提取关键词"><span class="post-toc-text">TF-IDF: 提取关键词</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#LDA-主题模型"><span class="post-toc-text">LDA: 主题模型</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#总结"><span class="post-toc-text">总结</span></a></li></ol>
			</nav>
			<div class="post-toc-bar"><div>
		</div></div></aside>
	

	</div>
</div>
		</div>
		</main>
		
		<!--footer-->
		<footer>
	<div class="blog-text-center">
		<div class="theme-annie-social">
				
				
					<a href="https://github.com/miraitowa" title="Github" target="_blank"><i class="fa fa-github"></i>&nbsp;</a>
					
				
				
					<a href="https://miraitowa.github.io/about/" title="Email" target="_blank"><i class="fa fa-envelope-o"></i>&nbsp;</a>
					
					
						
				
		</div>
	</div>

	<div class="blog-text-center">
		<div class="theme-annie-copyright">
			
				&copy; 2018 11 11 - 2019, content by miraitowa. All Rights Reserved.			       	
			
		</div>
	</div>

	<div class="blog-text-center">
		<div class="theme-annie-copyright">
			<a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> Theme <a href="https://github.com/Sariay/hexo-theme-Annie" title="Annie" target="_blank" rel="noopener">Annie</a> by Sariay.		
		</div>
	</div>
</footer>
		<!-- <script src="http://code.jquery.com/jquery-2.1.1.min.js" type="text/javascript"></script> -->

<script>
	window.jQuery || document.write('<script src="/js/jquery-2.1.1.min.js"><\/script>')
</script>

<style>
	.motto {
		color: #000000;
		font-size: 20px;
		margin: 100px 25% 0;
		width: 50%;
		line-height: 1.4;
		font-family:"KaiTi", "STXingkai", "Source Sans Pro", "Segoe UI", "Lucida Grande", Helvetica, Arial, "Microsoft YaHei", FreeSans, Arimo, "Droid Sans", "wenquanyi micro hei", "Hiragino Sans GB", "Hiragino Sans GB W3", FontAwesome, sans-serif;
		text-align: center;
	}
	@media(max-width: 890px) {
		.motto {	
			margin: 100px 10% 0;
			width: 80%;
		}
	}
	@media(max-width: 890px) {
		.motto {
			margin: 100px 5% 0;
			width: 90%;
		}
	}
</style>


	<script src="/js/motto.js"></script>
	<script type="text/javascript">
		$(".motto").html(getMingYanContent());
	</script>	







	<script type="text/javascript" src="/js/toc.js"></script>


<script type="text/javascript" src="/js/main.js"></script>

<script type="text/javascript">
	//generate a random img that pre_name 'from 0 to 110'
	var random_bg = Math.floor(Math.random() * 109 + 1);

	//var bg = 'url(/img/random/' + random_bg + '.jpg)';		
	var bg = 'url(https://miraitowa.github.io/Random-img/' + random_bg + '.jpg)';

	$("#header-bg-2").css("background-image", bg);
</script>
		
		<!--back to top-->
        <style type="text/css">
	#totop {
		background: white;
		border-radius: 50%;
		position: fixed;
		right: 5.4%;
		bottom: 80px;
		cursor: pointer;
	}
	
	#totop a {
		color: #474747;
		background-color: transparent;
		padding: 10px;
		text-decoration: none;
	}
	
	@media(max-width:512px) {
		#totop {
			display: none;
			visibility: hidden;
		}
	}
</style>


	<div id="totop">
  		<a href="javascript:;" class="fa fa-arrow-up"></a>
	</div>

	</body>
	</html>

